# Module 2: Foundation models

Modern NLP architectures are based on general-purpose models that are trained on large amounts of broad-coverage data and are adaptable to a wide range of downstream tasks. This module introduces the basic ideas behind these models and their use for practical applications.

## Unit 2-1: Introduction to generation and translation (78 min)

* Introduction to generation tasks [[slides](slides/slides-211.pdf)] [[video](https://youtu.be/rQgA09R8kSM)] (12:36)
* Evaluation of generation systems [[slides](slides/slides-212.pdf)] [[video](https://youtu.be/pJHmKn2FDRY)] (20:43)
* Introduction to machine translation [[slides](slides/slides-213.pdf)] [[video](https://youtu.be/P5KMKApthuM)] (18:25)
* Neural machine translation [[slides](slides/slides-214.pdf)] [[video](https://youtu.be/BqKbbygwsVc)] (16:29)
* Attention [[slides](slides/slides-215.pdf)] [[video](https://youtu.be/_OVzHikqiu4)] (12:13)

**Reading:**

* Eisenstein, chapter 6
* Papers on attention: [Cheng et al. (2016)](https://www.aclweb.org/anthology/D16-1053/), [Vaswani et al. (2017)](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf), [Serrano and Smith (2019)](https://www.aclweb.org/anthology/D18-1216/)

## Unit 2-2: Transformer models

## Unit 2-3: More applications of generation

* Summarization [[slides](http://www.cse.chalmers.se/~richajo/dat450/lectures/l12/l12_1.pdf)] [[video](https://youtu.be/EUJlrdJhBJg)]
* Dialogue systems [[slides](slides/slides-2022-232.pdf)] [[video](https://youtu.be/jWkQLVN3ixI)]

**Reading:**
* [Eisenstein](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf), chapter 19
* [Roller et al (2021)](https://aclanthology.org/2021.eacl-main.24/)

## Unit 2-4: Out-of distribution scenarios and domain adaptation

* Introduction to domain adaptation [[slides](http://www.cse.chalmers.se/~richajo/dat450/lectures/l13/l13_1.pdf)] [[video](https://youtu.be/C-Liu_qvavY)]
* Domain-adversarial training [[slides](http://www.cse.chalmers.se/~richajo/dat450/lectures/l13/l13_2.pdf)] [[video](https://youtu.be/Ei9JY06nepo)]
* Pseudo-labeling for domain adaptation [[slides](http://www.cse.chalmers.se/~richajo/dat450/lectures/l13/l13_3.pdf)] [[video](https://youtu.be/us7l7xvGQ-U)]
* Fine-tuning for adaptation

**Reading:**
* [Plank and Ramponi (2020)](https://aclanthology.org/2020.coling-main.603/)
