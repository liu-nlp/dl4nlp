# Deep Learning for Natural Language Processing

This is the website for the [WASP](https://wasp-sweden.org/) course “Deep Learning for Natural Language Processing”, taught by [Marco Kuhlmann](https://www.ida.liu.se/~marku61/) (Linköping University) and [Richard Johansson](http://www.cse.chalmers.se/~richajo/) (Chalmers University of Technology).

## Learning outcomes

Natural Language Processing (NLP) develops methods for making human language accessible to computers. The goal of this course is to provide students with a theoretical understanding of and practical experience with the advanced algorithms that power modern NLP. The course focuses on methods based on deep neural networks.

On completion of the course, you will be able to

* explain and analyze state-of-the-art deep learning architectures for NLP
* implement such architectures and apply them to practical problems
* design and carry out evaluations of deep learning architectures for NLP
* use current approaches to NLP in your own field of research

## Course literature

Yoav Goldberg, [Neural Network Methods for Natural Language Processing](https://www.morganclaypool.com/doi/abs/10.2200/S00762ED1V01Y201703HLT037). Morgan Claypool, 2017. [Pre-print version](https://arxiv.org/abs/1510.00726)

Jacob Eisenstein, [Natural Language Processing](https://mitpress.mit.edu/books/introduction-natural-language-processing). MIT Press, 2019. [Pre-print version](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)

Much of the content of the course is not described in a book, so we will also give pointers to research papers and survey articles when needed.

## Modules

The course consists of three thematic modules and a final project. The content of each module consists of
* video lectures introducing the important topics
* pointers to literature, some of which is fundamental and some optional
* a set of programming exercises
* a set of discussion tasks
* an assignment where you implement a model

### Module 1: Word representations

This module introduces one of the most fundamental ideas in modern NLP: the idea that words can be represented as vectors which can be learned from text data. On the application side of things, we focus on one of the most fundamental NLP tasks: text categorization.

[Detailed information about Module 1](module1.md)

### Module 2: Foundation models

Modern NLP architectures are based on general-purpose models that are trained on large amounts of broad-coverage data and are adaptable to a wide range of downstream tasks. This module introduces the basic ideas behind these models and their use for practical applications.

<!--[Detailed information about Module 2](module2.md)-->

### Module 3: Structured prediction

This module focuses on architectures and algorithms for NLP tasks where the goal is to predict a structured object such a sequence or a tree. Applications include well-known use cases such as named entity recognition and relation extraction.

<!--[Detailed information about Module 3](module3.md)-->

### Project

In the project, you apply your learning in the course to your own field of research.
